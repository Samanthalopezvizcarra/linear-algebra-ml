# üßÆ √Ålgebra Lineal Aplicada a Machine Learning

Proyecto de √Ålgebra Lineal que combina teor√≠a matem√°tica con aplicaciones pr√°cticas de machine learning en la compa√±√≠a de seguros **Sure Tomorrow**.

---

## üìò Descripci√≥n del proyecto
El objetivo del proyecto es demostrar aplicaciones del √°lgebra lineal en machine learning mediante varias tareas basadas en datos de clientes de seguros. Se trabaja con el dataset `/datasets/insurance_us.csv` que contiene informaci√≥n sobre:

**Caracter√≠sticas:**  
- Sexo  
- Edad  
- Salario  
- N√∫mero de familiares  

**Objetivo:** N√∫mero de beneficios de seguro recibidos por persona en los √∫ltimos cinco a√±os.

Las tareas a desarrollar incluyen:

1. **Encontrar clientes similares** a un cliente determinado para ayudar en marketing.  
2. **Predecir probabilidad de recibir un beneficio de seguro** y comparar con un modelo dummy.  
3. **Predecir la cantidad de beneficios esperados** mediante regresi√≥n lineal.  
4. **Proteger los datos personales** mediante ofuscaci√≥n sin afectar la calidad del modelo.  

---

## üõ†Ô∏è Proceso del proyecto

### 1. Preparaci√≥n de datos
- Carga y exploraci√≥n del dataset.  
- Verificaci√≥n de valores faltantes, outliers y consistencia de los datos.  
- Escalado de caracter√≠sticas para tareas basadas en distancias (kNN).

---

### 2. Tarea 1: B√∫squeda de clientes similares
- Escalado de datos balancea la influencia de variables grandes (`income`) y peque√±as (`age`).  
- Se prob√≥ distancia Manhattan; con estos datos la elecci√≥n fue indistinta, aunque en otros datasets puede afectar el desempe√±o.  

---

### 3. Tarea 2: Predicci√≥n de probabilidad de recibir beneficio
- Modelo kNN vs modelo Dummy.  
- Resultados para k=1:
  - Datos originales: F1 = 0.6  
  - Datos escalados: F1 = 0.92  
- Con k m√°s alto, el F1 de datos originales disminuye mientras que con datos escalados se mantiene alto.  
- Conclusi√≥n: **escalado de variables es crucial para kNN**, asegurando estabilidad y mejores predicciones.

---

### 4. Tarea 3: Predicci√≥n de cantidad de beneficios (Regresi√≥n Lineal)
- Datos originales: RMSE = 0.34, R¬≤ = 0.43 ‚Üí buen ajuste.  
- Datos escalados: R¬≤ cerca de 0 ‚Üí la normalizaci√≥n afecta la soluci√≥n anal√≠tica simple.  
- Conclusi√≥n: **Regresi√≥n lineal funciona mejor con datos originales** en esta implementaci√≥n, aunque el escalado puede ser √∫til en otros contextos o librer√≠as.

---

### 5. Tarea 4: Protecci√≥n de datos (Ofuscaci√≥n)
- Se aplic√≥ una **transformaci√≥n lineal invertible** a los datos.  
- Resultados:
  - RMSE y R¬≤ id√©nticos entre datos originales y ofuscados.  
  - Los coeficientes individuales cambian, pero las predicciones y calidad del modelo permanecen iguales.  
- Conclusi√≥n: La ofuscaci√≥n protege la privacidad sin afectar la precisi√≥n de la regresi√≥n lineal.

---

## üèÜ Resultados principales
- kNN con datos escalados supera al modelo Dummy en todas las configuraciones.  
- Regresi√≥n lineal es efectiva con datos originales para predecir beneficios esperados.  
- Ofuscaci√≥n de datos garantiza privacidad manteniendo la exactitud de predicciones.  

---

## üß∞ Tecnolog√≠as utilizadas
- Python  
- pandas ¬∑ numpy  
- scikit-learn  
- matplotlib / seaborn  
